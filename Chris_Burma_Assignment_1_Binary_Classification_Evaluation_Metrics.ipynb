{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d37a6bc0",
      "metadata": {
        "id": "d37a6bc0"
      },
      "source": [
        "# Assignment 1 - Binary Classification Evaluation Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1679a82",
      "metadata": {
        "id": "d1679a82"
      },
      "source": [
        "**Objective:**\n",
        "The objective of this assignment is to assess your understanding of fundamental concepts in model evaluation for machine learning tasks. This assignment covers topics discussed in the first half of the course, including key evaluation metrics, confusion matrices, ROC curves, and Precision-Recall curves.\n",
        "Instructions:\n",
        "\n",
        "1. Theory Questions:\n",
        "Answer the following theoretical questions:\n",
        "\n",
        "    1. Explain the limitations of accuracy as an evaluation metric in imbalanced datasets. How does accuracy behave when classes are heavily skewed, and why might it provide misleading results?\n",
        "    2. Describe the purpose and interpretation of a confusion matrix. How does it help in assessing a classification model's performance?\n",
        "    3. Explain the concept of ROC curves. What does each point on an ROC curve represent? How is the area under the ROC curve (AUC-ROC) calculated?\n",
        "    4. Compare and contrast the advantages and disadvantages of ROC curves and Precision-Recall curves. In what scenarios would you prefer to use one over the other, and why?\n",
        "\n",
        "2. Practical Exercises:\n",
        "* Implement Python code to calculate the following evaluation metrics for a given binary classification problem: Log Loss\n",
        "* Select the best metric for an applied scenario\n",
        "\n",
        "**Submission Guidelines:**\n",
        "* Submit your responses to the theory questions in a neatly organized markdown.\n",
        "* Include your Python code for the practical exercise.\n",
        "* Submit your assignment as a single `.ipynb` file named `MY NAME Assignment 1 - Log Loss` via the course submission platform (slack)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e58864fe",
      "metadata": {
        "id": "e58864fe"
      },
      "source": [
        "## Part 1: Theory Questions (20 points)\n",
        "Provide your answers here:\n",
        "\n",
        "    1. In an imbalanced scenario, a model can achieve high accuracy simply by predicting the majority class all the time, even if it performs poorly on the minority class. In class, we've used the fraud example. Say we're building a model to detect fraud, where only 2% of transactions are actually fraudulent. If a model predicts \"Not Fraud\" for every transaction it will be correct 98% of the time, but completely fails to detect actual fraud cases.\n",
        "    2. A confusion matrix is a tool used to evaluate the performance of a classification model by comparing the model's predictions with the actual class labels. It provides a detailed breakdown of correct and incorrect classifications for each class, such as TP, TN, FP, FN. These help accuracy predict performance metrics like accuracy and precision.\n",
        "    3. An ROC curve is a graphical representation used to evaluate the performance of a binary classification model. A curve closer to the top-left corner indicates better performance. The AUC-ROC is a single scalar value summarizing the model's ability to discriminate between the positive and negative classes across all thresholds. 1.0 is the perfect score for this curve.\n",
        "    4. The advantages of the ROC Curve are that it gives a comprehensive view of model performance and it is less sensitive to class imbalance. For the PR curve, it is better at showing how well the model identifies the positive class, especially when it's rare. The disadvantaces of ROC is that it can be overly optimistic with highly imbalanced datasets, and the disadvantages of the PR Curve are that it can be harder to interpret since precision and recall vary significantly based on class distribution. These are just a couple of examples - there are many more advantages and disadvantages of both curves.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b8c2adb",
      "metadata": {
        "id": "8b8c2adb"
      },
      "source": [
        "## Practicing Log Loss (25 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f4dca41",
      "metadata": {
        "id": "2f4dca41"
      },
      "source": [
        "**Objective:**\n",
        "The objective of this assignment is to deepen your understanding of log loss, also known as logarithmic loss or cross-entropy loss, and its application in evaluating the performance of classification models.\n",
        "\n",
        "**Instructions:**\n",
        "In this assignment, you will be given a set of binary classification predictions along with their corresponding actual class labels. Your task is to calculate the log loss for each prediction and then analyze the overall log loss performance of the model.\n",
        "\n",
        "**Dataset:**\n",
        "You are provided with a dataset containing the following information:\n",
        "\n",
        "Predicted probabilities for the positive class (ranging from 0 to 1) for a set of instances.\n",
        "Actual binary class labels (0 or 1) indicating whether the instance belongs to the positive class or not.\n",
        "\n",
        "**Assignment Tasks:**\n",
        "1. Calculate the log loss for each instance in the dataset using the predicted probabilities and actual class labels.\n",
        "2. Summarize the individual log losses and compute the overall log loss performance for the model.\n",
        "3. Interpret the overall log loss value and analyze the model's performance. Discuss any insights or observations derived from the log loss analysis.\n",
        "\n",
        "\n",
        "**Dataset:**\n",
        "\n",
        "| Instance | Predicted Probability | Actual Label |\n",
        "|----------|------------------------|--------------|\n",
        "|    1     |          0.9           |       1      |\n",
        "|    2     |          0.3           |       0      |\n",
        "|    3     |          0.6           |       1      |\n",
        "|    4     |          0.8           |       0      |\n",
        "|    5     |          0.1           |       1      |\n",
        "\n",
        "\n",
        "**Grading Criteria:**\n",
        "\n",
        "* Correctness of log loss calculations.\n",
        "* Clarity and completeness of the analysis.\n",
        "* Insights derived from the log loss interpretation.\n",
        "* Overall presentation and adherence to submission guidelines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3dad6832",
      "metadata": {
        "id": "3dad6832",
        "outputId": "734ad1e5-fc5c-4c93-d204-ba6c9aca484f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Instance  Predicted Probability  Actual Label\n",
            "0         1                    0.9             1\n",
            "1         2                    0.3             0\n",
            "2         3                    0.6             1\n",
            "3         4                    0.8             0\n",
            "4         5                    0.1             1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame with the dataset\n",
        "data = {\n",
        "    'Instance': [1, 2, 3, 4, 5],\n",
        "    'Predicted Probability': [0.9, 0.3, 0.6, 0.8, 0.1],\n",
        "    'Actual Label': [1, 0, 1, 0, 1]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9be2a3c3",
      "metadata": {
        "id": "9be2a3c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7171899d-3644-44a8-9e61-1f22eb162e71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Log Loss (scikit-learn): 0.97698\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "predicted_probs = [0.9, 0.3, 0.6, 0.8, 0.1]\n",
        "actual_labels = [1, 0, 1, 0, 1]\n",
        "\n",
        "loss = log_loss(actual_labels, predicted_probs)\n",
        "print(f\"Overall Log Loss (scikit-learn): {loss:.5f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eaa92db1",
      "metadata": {
        "id": "eaa92db1"
      },
      "source": [
        "*Question: Interpret the log loss above. How would it change if the predicted probability for instance 0 changed from 0.9 to 0.6? Why?*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2abec414",
      "metadata": {
        "id": "2abec414"
      },
      "source": [
        "*Your answer:* The change in predicted probability would increase the log loss. Log loss rewards confident correct predictions and penalizes uncertain or incorrect predictions. Changing the probability to 0.6 means the model is now less confident in a correct prediction making the log loss higher.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "972c7485",
      "metadata": {
        "id": "972c7485"
      },
      "source": [
        "*Question: Why might you select log loss over precision, recall, or accuracy (in the context of any problem, not this one specifically)?*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88b26ee2",
      "metadata": {
        "id": "88b26ee2"
      },
      "source": [
        "*Your answer:* You might want to select log loss over precision, recall, and accuracy because log loss works with imbalanced data sets. Also, it does a great job evaluating probabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a69ed6d7",
      "metadata": {
        "id": "a69ed6d7"
      },
      "source": [
        "## Application Scenario: Select a Metric (55 points)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pIIgLaJ1avA0"
      },
      "id": "pIIgLaJ1avA0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "791158c2",
      "metadata": {
        "id": "791158c2"
      },
      "source": [
        "**Application Scenario: Fraud Detection System**\n",
        "\n",
        "You are working as a data scientist for a financial institution that wants to develop a fraud detection system to identify potentially fraudulent transactions. The dataset contains information about various transactions, including transaction amount, merchant ID, and transaction type. Your task is to build a machine learning model to classify transactions as either fraudulent or non-fraudulent.\n",
        "\n",
        "**Problem Description:**\n",
        "\n",
        "* Dataset: The dataset consists of historical transaction data, with labels indicating whether each transaction was fraudulent or not.\n",
        "* Class Distribution: The dataset is mostly non-fraudulant cases, with a small percentage of transactions being fraudulent compared to legitimate transactions.\n",
        "* Objective: The objective is to develop a fraud detection model that minimizes false negatives (fraudulent transactions incorrectly classified as non-fraudulent) while maintaining a reasonable level of precision.\n",
        "\n",
        "**Stakeholder Requirements:**\n",
        "Given the nature of the problem, it is crucial to prioritize recall (sensitivity) to ensure that as many fraudulent transactions as possible are detected. However, precision is also important to minimize false positives and avoid unnecessary investigations of legitimate transactions. Minimizing false negatives (missing fraudulent transactions) is of utmost importance.\n",
        "\n",
        "**Task:**\n",
        "Your task is to develop Python code to evaluate the performance of different machine learning models using various evaluation metrics, including accuracy, precision, recall, and F2 score. *Select the evaluation metric that best suits the problem and explain your choice*.\n",
        "\n",
        "**Additional Guidelines:**\n",
        "* You should preprocess the dataset as needed and split it into training and testing sets.\n",
        "* Implement machine learning models of your choice (e.g., logistic regression, random forest) and evaluate their performance.\n",
        "* Use appropriate evaluation metrics for binary classification tasks.\n",
        "* Discuss the rationale behind your choice of evaluation metric and how it aligns with the problem requirements.\n",
        "* Present your findings and recommendations for selecting the best model based on the chosen evaluation metric."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc4f0e46",
      "metadata": {
        "id": "dc4f0e46"
      },
      "source": [
        "**Dataset Sample:**\n",
        "\n",
        "| Transaction ID | Transaction Amount | Merchant ID | Transaction Type | Fraudulent |\n",
        "|----------------|--------------------|-------------|------------------|------------|\n",
        "| 1              | 1000               | M123        | Online Purchase  | 0          |\n",
        "| 2              | 500                | M456        | ATM Withdrawal   | 0          |\n",
        "| 3              | 2000               | M789        | Online Purchase  | 1          |\n",
        "| 4              | 1500               | M123        | POS Transaction  | 0          |\n",
        "| 5              | 800                | M456        | Online Purchase  | 0          |\n",
        "| 6              | 3000               | M789        | ATM Withdrawal   | 1          |\n",
        "\n",
        "* Transaction ID: Unique identifier for each transaction.\n",
        "* Transaction Amount: The amount of money involved in the transaction.\n",
        "* Merchant ID: Identifier for the merchant involved in the transaction.\n",
        "* Transaction Type: The type of transaction (e.g., online purchase, ATM withdrawal, POS transaction).\n",
        "* Fraudulent: Binary indicator (0 or 1) specifying whether the transaction is fraudulent (1) or not (0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1bc1ec81",
      "metadata": {
        "id": "1bc1ec81",
        "outputId": "ba80e5ce-3257-498e-ad1c-72d01d4ff899",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Transaction ID  Transaction Amount Merchant ID Transaction Type  \\\n",
            "0                1                1000        M123  Online Purchase   \n",
            "1                2                 500        M456   ATM Withdrawal   \n",
            "2                3                2000        M789  Online Purchase   \n",
            "3                4                1500        M123  POS Transaction   \n",
            "4                5                 800        M456  Online Purchase   \n",
            "5                6                3000        M789   ATM Withdrawal   \n",
            "6                7                1200        M123  Online Purchase   \n",
            "7                8                 700        M456   ATM Withdrawal   \n",
            "8                9                1800        M789  Online Purchase   \n",
            "9               10                1300        M123  POS Transaction   \n",
            "10              11                 900        M456  Online Purchase   \n",
            "11              12                 400        M789   ATM Withdrawal   \n",
            "12              13                2200        M123  Online Purchase   \n",
            "13              14                1600        M456   ATM Withdrawal   \n",
            "14              15                 850        M789  Online Purchase   \n",
            "15              16                2800        M123  POS Transaction   \n",
            "16              17                1100        M456  Online Purchase   \n",
            "17              18                 600        M789   ATM Withdrawal   \n",
            "18              19                1900        M123  Online Purchase   \n",
            "19              20                1400        M456   ATM Withdrawal   \n",
            "20              21                 950        M123  Online Purchase   \n",
            "21              22                 300        M456   ATM Withdrawal   \n",
            "22              23                2100        M789  Online Purchase   \n",
            "23              24                1700        M123  POS Transaction   \n",
            "24              25                 820        M456  Online Purchase   \n",
            "25              26                3200        M789   ATM Withdrawal   \n",
            "26              27                1250        M123  Online Purchase   \n",
            "27              28                 720        M456   ATM Withdrawal   \n",
            "28              29                1850        M789  Online Purchase   \n",
            "29              30                1350        M123  POS Transaction   \n",
            "30              31                 880        M456  Online Purchase   \n",
            "31              32                 420        M789   ATM Withdrawal   \n",
            "32              33                2400        M123  Online Purchase   \n",
            "33              34                1750        M456   ATM Withdrawal   \n",
            "34              35                 830        M789  Online Purchase   \n",
            "35              36                3100        M123  POS Transaction   \n",
            "36              37                1150        M456  Online Purchase   \n",
            "37              38                 620        M789   ATM Withdrawal   \n",
            "38              39                1950        M123  Online Purchase   \n",
            "39              40                1450        M456   ATM Withdrawal   \n",
            "\n",
            "    Fraudulent  \n",
            "0            0  \n",
            "1            0  \n",
            "2            1  \n",
            "3            0  \n",
            "4            0  \n",
            "5            1  \n",
            "6            0  \n",
            "7            0  \n",
            "8            1  \n",
            "9            0  \n",
            "10           0  \n",
            "11           1  \n",
            "12           0  \n",
            "13           0  \n",
            "14           1  \n",
            "15           0  \n",
            "16           0  \n",
            "17           1  \n",
            "18           0  \n",
            "19           0  \n",
            "20           1  \n",
            "21           0  \n",
            "22           0  \n",
            "23           1  \n",
            "24           0  \n",
            "25           0  \n",
            "26           1  \n",
            "27           0  \n",
            "28           0  \n",
            "29           1  \n",
            "30           0  \n",
            "31           0  \n",
            "32           1  \n",
            "33           0  \n",
            "34           0  \n",
            "35           1  \n",
            "36           0  \n",
            "37           0  \n",
            "38           1  \n",
            "39           0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Creating the dataset\n",
        "data = {\n",
        "    'Transaction ID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
        "                       11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
        "                       21, 22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
        "                       31, 32, 33, 34, 35, 36, 37, 38, 39, 40],\n",
        "    'Transaction Amount': [1000, 500, 2000, 1500, 800, 3000, 1200, 700, 1800, 1300,\n",
        "                           900, 400, 2200, 1600, 850, 2800, 1100, 600, 1900, 1400,\n",
        "                           950, 300, 2100, 1700, 820, 3200, 1250, 720, 1850, 1350,\n",
        "                           880, 420, 2400, 1750, 830, 3100, 1150, 620, 1950, 1450],\n",
        "    'Merchant ID': ['M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123',\n",
        "                    'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456',\n",
        "                    'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123',\n",
        "                    'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456'],\n",
        "    'Transaction Type': ['Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'POS Transaction', 'Online Purchase',\n",
        "                         'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'POS Transaction',\n",
        "                         'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase',\n",
        "                         'POS Transaction', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal',\n",
        "                         'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'POS Transaction', 'Online Purchase',\n",
        "                         'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'POS Transaction',\n",
        "                         'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase',\n",
        "                         'POS Transaction', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal'],\n",
        "    'Fraudulent': [0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
        "                   0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
        "                   1, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
        "                   0, 0, 1, 0, 0, 1, 0, 0, 1, 0]\n",
        "}\n",
        "\n",
        "# Creating DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Displaying the DataFrame\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4eb158cb",
      "metadata": {
        "id": "4eb158cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df0adfd0-da2b-4e59-923b-cca104b6202c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Accuracy  Precision  Recall  F2 Score\n",
            "Logistic Regression  0.583333   0.333333    0.25  0.263158\n",
            "Random Forest        0.500000   0.250000    0.25  0.250000\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, fbeta_score\n",
        "\n",
        "# Data from above\n",
        "data = {\n",
        "    'Transaction ID': list(range(1, 41)),\n",
        "    'Transaction Amount': [1000, 500, 2000, 1500, 800, 3000, 1200, 700, 1800, 1300,\n",
        "                           900, 400, 2200, 1600, 850, 2800, 1100, 600, 1900, 1400,\n",
        "                           950, 300, 2100, 1700, 820, 3200, 1250, 720, 1850, 1350,\n",
        "                           880, 420, 2400, 1750, 830, 3100, 1150, 620, 1950, 1450],\n",
        "    'Merchant ID': ['M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123',\n",
        "                    'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456',\n",
        "                    'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123',\n",
        "                    'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456'],\n",
        "    'Transaction Type': ['Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'POS Transaction', 'Online Purchase',\n",
        "                         'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'POS Transaction',\n",
        "                         'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase',\n",
        "                         'POS Transaction', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal',\n",
        "                         'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'POS Transaction', 'Online Purchase',\n",
        "                         'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'POS Transaction',\n",
        "                         'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase',\n",
        "                         'POS Transaction', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal'],\n",
        "    'Fraudulent': [0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
        "                   0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
        "                   1, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
        "                   0, 0, 1, 0, 0, 1, 0, 0, 1, 0]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "X = df.drop(columns=['Transaction ID', 'Fraudulent'])\n",
        "y = df['Fraudulent']\n",
        "\n",
        "X_encoded = pd.get_dummies(X, columns=['Merchant ID', 'Transaction Type'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    results[name] = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall\": recall_score(y_test, y_pred),\n",
        "        \"F2 Score\": fbeta_score(y_test, y_pred, beta=2)\n",
        "    }\n",
        "\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In Summary**: My findings are that it'd be best to use the F2 Score as the evaluation metric. The problem prioritizes catching fraud (recall) while also caring about not overwhelming investigators (precision).\n",
        "\n",
        "F2 gives 2x more weight to recall, making it ideal for this context where missing fraud is riskier than investigating a few false alarms."
      ],
      "metadata": {
        "id": "JIbYvPaGeeOc"
      },
      "id": "JIbYvPaGeeOc"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}